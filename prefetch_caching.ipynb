{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WohH6cDoSmt"
      },
      "source": [
        "<h3 align=\"center\" style='color:blue'>Optimize tensorflow pipeline performance with prefetch and caching</h3>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjfCcKEVoU-1",
        "outputId": "6368a0ea-784c-40de-fc5c-e796b77f6005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrTOP0R5oSmv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xpFQHRX1oSmx",
        "outputId": "567011f1-23dc-4f01-e9c1-b12f99e1b08d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.15.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gmckgt4oSmz"
      },
      "source": [
        "<h3 style='color:purple'>Prefetch</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FP-sE8z4oSm0"
      },
      "outputs": [],
      "source": [
        "class FileDataset(tf.data.Dataset):\n",
        "    def read_file_in_batches(num_samples):\n",
        "        # Opening the file\n",
        "        time.sleep(0.03)\n",
        "\n",
        "        for sample_idx in range(num_samples):\n",
        "            # Reading data (line, record) from the file\n",
        "            time.sleep(0.015)\n",
        "\n",
        "            yield (sample_idx,)\n",
        "\n",
        "    def __new__(cls, num_samples=3):\n",
        "        return tf.data.Dataset.from_generator(\n",
        "            cls.read_file_in_batches,\n",
        "            output_signature = tf.TensorSpec(shape = (1,), dtype = tf.int64),\n",
        "            args=(num_samples,)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAiKpCT3oSm0"
      },
      "outputs": [],
      "source": [
        "def benchmark(dataset, num_epochs=2):\n",
        "    for epoch_num in range(num_epochs):\n",
        "        for sample in dataset:\n",
        "            # Performing a training step\n",
        "            time.sleep(0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmCygXY1oSm0",
        "outputId": "8465dc1f-adbd-40d2-da25-a0a358cc0fb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "306 ms ± 29.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "benchmark(FileDataset())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mijD1g5IoSm0",
        "outputId": "aa4adc39-1444-493b-e939-d76793ddf92c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "283 ms ± 23.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "benchmark(FileDataset().prefetch(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW9oeTMjoSm1",
        "outputId": "f5e8b6c9-a400-4eaa-bafe-212152333183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313 ms ± 21.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "benchmark(FileDataset().prefetch(tf.data.AUTOTUNE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fexvErE6oSm1"
      },
      "source": [
        "**As you can notice above, using prefetch improves the performance from 304 ms to 238 and 240 ms**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-AoaBDaoSm1"
      },
      "source": [
        "<h3 style='color:purple'>Cache</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swV7T3_5oSm1",
        "outputId": "da4b244f-cc97-4b26-d892-23bf9bda7466"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 4, 9, 16]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "dataset = tf.data.Dataset.range(5)\n",
        "dataset = dataset.map(lambda x: x**2)\n",
        "dataset = dataset.cache(\"mycache.txt\")\n",
        "# The first time reading through the data will generate the data using\n",
        "# `range` and `map`.\n",
        "list(dataset.as_numpy_iterator())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXqD-0BloSm1",
        "outputId": "4af83dcd-745a-482c-c925-93fbc210a2f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 4, 9, 16]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Subsequent iterations read from the cache.\n",
        "list(dataset.as_numpy_iterator())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RFudAaXoSm1"
      },
      "outputs": [],
      "source": [
        "def mapped_function(s):\n",
        "    # Do some hard pre-processing\n",
        "    tf.py_function(lambda: time.sleep(0.03), [], ())\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES1h9ThuoSm1",
        "outputId": "0e5c6168-926a-46b3-8947-199890e7090f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.47 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -r1 -n1\n",
        "benchmark(FileDataset().map(mapped_function), 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdek8WW7oSm2",
        "outputId": "9b257dfd-67e7-42af-a7cd-e46c908c2fdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "507 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -r1 -n1\n",
        "benchmark(FileDataset().map(mapped_function).cache(), 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IE0vjAYoSm2"
      },
      "source": [
        "**Further reading** https://www.tensorflow.org/guide/data_performance#caching"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}